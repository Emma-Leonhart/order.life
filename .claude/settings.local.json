{
  "permissions": {
    "allow": [
      "Bash(git add:*)",
      "Bash(git commit:*)",
      "WebFetch(domain:www.wikidata.org)",
      "WebSearch",
      "Bash(\"C:\\\\Users\\\\Immanuelle\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python.exe\" fetch_first_level_divisions.py)",
      "Bash(\"C:\\\\Users\\\\Immanuelle\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python.exe\" analyze_instance_types.py)",
      "Bash(\"C:\\\\Users\\\\Immanuelle\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python.exe\" analyze_property_coverage.py)",
      "Bash(\"C:\\\\Users\\\\Immanuelle\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python.exe\" enrich_divisions_csv.py)",
      "Bash(\"C:\\\\Users\\\\Immanuelle\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python.exe\" check_p131_issue.py)",
      "Bash(\"\n- Literals \\(coordinates, dates, IDs\\) stored directly\n\nKey properties included:\n- P17 country \\(97.8%\\), P625 coordinates \\(76.5%\\)\n- P36 capital \\(69.1%\\), P2046 area \\(67.3%\\), P1082 population \\(60.7%\\)\n- P18 image \\(49.4%\\), P571 inception \\(48.6%\\), P47 borders \\(48.6%\\)\n- P41 flag \\(30.5%\\), P94 coat of arms \\(32.6%\\), P1705 native label \\(30.2%\\)\n- Plus 38 more properties\n\nAlso adds check_p131_issue.py which investigates P131 values - most \\(69%\\)\ncorrectly point to countries, with some pointing to historical entities\nlike Ottoman eyalets/vilayets.\n\nOutput: first_level_divisions_enriched.csv \\(5MB, 52 columns\\)\n\nCo-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(\"C:\\\\Users\\\\Immanuelle\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python.exe\" filter_historical_divisions.py)",
      "Bash(\"C:\\\\Users\\\\Immanuelle\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python.exe\" analyze_current_coverage.py)",
      "Bash(\"C:\\\\Users\\\\Immanuelle\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python.exe\" -c \"\nimport csv\nimport sys\nimport io\nsys.stdout = io.TextIOWrapper\\(sys.stdout.buffer, encoding=''utf-8''\\)\n\nwith open\\(''first_level_divisions_enriched.csv'', ''r'', encoding=''utf-8''\\) as f:\n    reader = csv.DictReader\\(f\\)\n    entities_with_p576 = []\n    for row in reader:\n        if row.get\\(''P576'', ''''\\).strip\\(\\):\n            entities_with_p576.append\\({\n                ''label'': row[''label''],\n                ''qid'': row[''qid''],\n                ''instance_of'': row[''instance_of_qid''],\n                ''P31'': row.get\\(''P31'', ''''\\),\n                ''P576'': row[''P576'']\n            }\\)\n\nprint\\(f''Entities with P576 \\(dissolved date\\): {len\\(entities_with_p576\\)}''\\)\nprint\\(\\)\nprint\\(''Sample of entities with P576:''\\)\nprint\\(''-'' * 100\\)\nfor e in entities_with_p576[:30]:\n    print\\(f\"\"{e[''qid'']:<12} {e[''label''][:35]:<36} P31: {e[''P31''][:40]:<41}\"\"\\)\n    print\\(f\"\"             P576: {e[''P576''][:80]}\"\"\\)\n    print\\(\\)\n\")",
      "Bash(\"C:\\\\Users\\\\Immanuelle\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python.exe\" -c:*)",
      "Bash(\"C:\\\\Users\\\\Immanuelle\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python.exe\" -c \"\nimport csv\nimport sys\nimport io\nsys.stdout = io.TextIOWrapper\\(sys.stdout.buffer, encoding=''utf-8''\\)\n\nwith open\\(''first_level_divisions_enriched.csv'', ''r'', encoding=''utf-8''\\) as f:\n    reader = csv.DictReader\\(f\\)\n    rows = list\\(reader\\)\n\ntotal = len\\(rows\\)\nprops = [''P17'',''P625'',''P242'',''P2046'',''P1082'',''P36'',''P300'',''P18'',''P47'',''P41'',''P94'',''P576'']\nlabels = [''country'',''coordinates'',''locator map'',''area'',''population'',''capital'',''ISO code'',''image'',''borders'',''flag'',''coat of arms'',''dissolved'']\n\nprint\\(f''Total: {total}''\\)\nprint\\(\\)\nfor p, label in zip\\(props, labels\\):\n    filled = sum\\(1 for r in rows if r.get\\(p,''''\\).strip\\(\\)\\)\n    pct = filled/total*100\n    print\\(f''{p:<6} {label:<15} {filled:>5} \\({pct:.1f}%\\)''\\)\n\")",
      "Bash(git remote remove:*)",
      "Bash(/c/Users/Immanuelle/AppData/Local/Programs/Python/Python313/python.exe build.py)",
      "Bash(git checkout:*)",
      "Bash(git push:*)",
      "Bash(ls:*)",
      "Bash(git ls-files:*)",
      "Bash(head:*)",
      "Bash(\"C:\\\\Users\\\\Immanuelle\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python.exe\" -c \"\nimport csv, json, re, glob, os\n\nrealms = {}  # qid -> name\n\n# Process all CSVs\nfor f in glob.glob\\(''realms/query*.csv''\\):\n    with open\\(f, ''r'', encoding=''utf-8''\\) as fh:\n        reader = csv.reader\\(fh\\)\n        header = next\\(reader\\)\n        for row in reader:\n            url = row[0]\n            label = row[1] if len\\(row\\) > 1 else ''''\n            m = re.search\\(r''/entity/\\(Q\\\\d+\\)'', url\\)\n            if m:\n                qid = m.group\\(1\\)\n                if label and label != qid:\n                    realms[qid] = label\n\n# Process query.json\nwith open\\(''realms/query.json'', ''r'', encoding=''utf-8''\\) as fh:\n    data = json.load\\(fh\\)\n    for item in data:\n        url = item.get\\(''prefecture'', ''''\\)\n        label = item.get\\(''prefectureLabel'', ''''\\)\n        m = re.search\\(r''/entity/\\(Q\\\\d+\\)'', url\\)\n        if m:\n            qid = m.group\\(1\\)\n            if label and label != qid:\n                realms[qid] = label\n\n# Sort by name, output\nresult = sorted\\([{''name'': name, ''qid'': qid} for qid, name in realms.items\\(\\)], key=lambda x: x[''name'']\\)\nprint\\(f''Total unique realms: {len\\(result\\)}''\\)\nprint\\(f''First 5: {result[:5]}''\\)\nprint\\(f''Last 5: {result[-5:]}''\\)\n\nwith open\\(''realms/realms.json'', ''w'', encoding=''utf-8''\\) as fh:\n    json.dump\\(result, fh, indent=2, ensure_ascii=False\\)\nprint\\(''Written to realms/realms.json''\\)\n\")",
      "Bash(\"C:\\\\Users\\\\Immanuelle\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python.exe\" -c \"\nimport csv, json, re, glob, os, sys\n\nrealms = {}  # qid -> name\n\n# Process all CSVs\nfor f in glob.glob\\(''realms/query*.csv''\\):\n    with open\\(f, ''r'', encoding=''utf-8''\\) as fh:\n        reader = csv.reader\\(fh\\)\n        header = next\\(reader\\)\n        for row in reader:\n            url = row[0]\n            label = row[1] if len\\(row\\) > 1 else ''''\n            m = re.search\\(r''/entity/\\(Q\\\\d+\\)'', url\\)\n            if m:\n                qid = m.group\\(1\\)\n                if label and label != qid:\n                    realms[qid] = label\n\n# Process query.json\nwith open\\(''realms/query.json'', ''r'', encoding=''utf-8''\\) as fh:\n    data = json.load\\(fh\\)\n    for item in data:\n        url = item.get\\(''prefecture'', ''''\\)\n        label = item.get\\(''prefectureLabel'', ''''\\)\n        m = re.search\\(r''/entity/\\(Q\\\\d+\\)'', url\\)\n        if m:\n            qid = m.group\\(1\\)\n            if label and label != qid:\n                realms[qid] = label\n\n# Sort by name, output\nresult = sorted\\([{''name'': name, ''qid'': qid} for qid, name in realms.items\\(\\)], key=lambda x: x[''name'']\\)\n\nwith open\\(''realms/realms.json'', ''w'', encoding=''utf-8''\\) as fh:\n    json.dump\\(result, fh, indent=2, ensure_ascii=False\\)\n\nsys.stdout.reconfigure\\(encoding=''utf-8''\\)\nprint\\(f''Total unique realms: {len\\(result\\)}''\\)\nprint\\(f''First 3: {result[:3]}''\\)\nprint\\(''Done.''\\)\n\")",
      "Bash(\"C:\\\\Users\\\\Immanuelle\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python.exe\" -c \"\nwith open\\(''build.py'', ''r'', encoding=''utf-8''\\) as f:\n    lines = f.readlines\\(\\)\n\n# Remove lines 325-421 \\(0-indexed: 324-420\\)\nnew_lines = lines[:324] + lines[421:]\n\nwith open\\(''build.py'', ''w'', encoding=''utf-8''\\) as f:\n    f.writelines\\(new_lines\\)\n\nprint\\(f''Removed {421-324} lines. File now has {len\\(new_lines\\)} lines.''\\)\n\")",
      "Bash(\"C:\\\\Users\\\\Immanuelle\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python.exe\" build.py)",
      "Bash(python:*)",
      "WebFetch(domain:query.wikidata.org)",
      "Bash(\"C:\\\\Users\\\\Immanuelle\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python.exe\":*)",
      "Bash(\"C:\\\\Users\\\\Immanuelle\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python.exe\" -c \"\nimport json, urllib.request, urllib.parse, time\n\nwith open\\(''C:/Users/ambie/Documents/Github/order.life/realms/realms.json'', ''r'', encoding=''utf-8''\\) as f:\n    realms = json.load\\(f\\)\n\nqids = [r[''qid''] for r in realms]\nprint\\(f''Total QIDs: {len\\(qids\\)}''\\)\n\nformer = set\\(\\)\nBATCH = 80\nfor i in range\\(0, len\\(qids\\), BATCH\\):\n    batch = qids[i:i+BATCH]\n    values = '' ''.join\\(f''wd:{q}'' for q in batch\\)\n    sparql = f''''''SELECT ?item WHERE {{\n      VALUES ?item {{ {values} }}\n      ?item wdt:P31 wd:Q19953632 .\n    }}''''''\n    url = ''https://query.wikidata.org/sparql?'' + urllib.parse.urlencode\\({''query'': sparql, ''format'': ''json''}\\)\n    req = urllib.request.Request\\(url, headers={''User-Agent'': ''OrderOfLifeBot/1.0'', ''Accept'': ''application/sparql-results+json''}\\)\n    with urllib.request.urlopen\\(req, timeout=60\\) as resp:\n        data = json.loads\\(resp.read\\(\\).decode\\(''utf-8''\\)\\)\n    for row in data[''results''][''bindings'']:\n        qid = row[''item''][''value''].split\\(''/''\\)[-1]\n        former.add\\(qid\\)\n    bn = i // BATCH + 1\n    print\\(f''  Batch {bn}: found {len\\([q for q in batch if q in former]\\)} former entities''\\)\n    if i + BATCH < len\\(qids\\):\n        time.sleep\\(2\\)\n\nprint\\(f''\\\\nTotal former entities to remove: {len\\(former\\)}''\\)\nfor q in sorted\\(former\\):\n    name = next\\(\\(r[''realm_name''] for r in realms if r[''qid''] == q\\), q\\)\n    print\\(f''  {q}: {name}''\\)\n\")",
      "Bash(git pull:*)",
      "Bash(git stash:*)",
      "Bash(\"C:\\\\Users\\\\Immanuelle\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python.exe\" -c \"import markdown; print\\(markdown.version\\)\")",
      "Bash(\"C:\\\\Users\\\\Immanuelle\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python.exe\" -m pip install markdown)",
      "Bash(gh run list:*)",
      "Bash(\"C:\\\\Users\\\\Immanuelle\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python.exe\" add_sacred_land_i18n.py)",
      "Bash(git rm:*)",
      "Bash(\"C:\\\\Users\\\\Immanuelle\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python.exe\" realms/enrich_realms.py)",
      "Bash(\"C:\\\\Users\\\\Immanuelle\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python.exe\" -c \":*)",
      "Bash(\"C:\\\\Users\\\\Immanuelle\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python.exe\" realms/normalize_realm_names.py)",
      "Bash(cat:*)",
      "WebFetch(domain:order.life)",
      "Bash(cd:*)",
      "Bash(cp:*)",
      "Bash(git:*)",
      "Bash(tail:*)",
      "Bash(node:*)",
      "WebFetch(domain:wiki.order.life)",
      "Bash(gh repo:*)",
      "Bash(gh repo view Emma-Leonhart/order.life --json defaultBranchRef,homepageUrl 2>&1 && gh api repos/Emma-Leonhart/order.life/pages 2>&1 && gh run list --repo Emma-Leonhart/order.life --limit 5 2>&1)",
      "Bash(echo curl failed:*)",
      "WebFetch(domain:api.github.com)",
      "WebFetch(domain:pypi.org)",
      "Bash(C:/Users/Immanuelle/AppData/Local/Programs/Python/Python313/python.exe:*)"
    ]
  }
}
